{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5cc75f6-1611-4b6d-987c-2dc50d35fb07",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652d2b98-5d85-4a8d-812a-a322b72c9c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c1265-ce3b-4646-91a4-ed9d89232576",
   "metadata": {},
   "source": [
    "### Artificial Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0f480e-9858-4d7c-87ce-796e0b720447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.84147098,  0.90929743,  0.14112001, -0.7568025 ,\n",
       "       -0.95892427, -0.2794155 ,  0.6569866 ,  0.98935825,  0.41211849,\n",
       "       -0.54402111, -0.99999021, -0.53657292,  0.42016704,  0.99060736,\n",
       "        0.65028784, -0.28790332, -0.96139749, -0.75098725,  0.14987721])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = np.sin(np.arange(0,20,1))\n",
    "sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0e22a-63d7-4315-845b-eb88b150bec9",
   "metadata": {},
   "source": [
    "### Test Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9bc76b-36cc-40b2-8f84-d26e729518df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_src_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e717a77-45e9-42cf-8bfa-f273d1c4a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = load_src_trg(sequence, 5, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629f25e5-6338-4314-b700-3af0693e4ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.8415,  0.9093,  0.1411, -0.7568]], dtype=torch.float64)\n",
      "tensor([[-0.7568, -0.9589, -0.2794,  0.6570,  0.9894]], dtype=torch.float64)\n",
      "tensor([[-0.9589, -0.2794,  0.6570,  0.9894,  0.4121]], dtype=torch.float64)\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for src, trg, trg_y in data_iter:\n",
    "    print(src)\n",
    "    print(trg)\n",
    "    print(trg_y)\n",
    "    print('-------')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b26f5-967e-40b0-8508-c397b887d9bc",
   "metadata": {},
   "source": [
    "### Test Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44373ea7-bfc7-4479-ab48-74c055a0f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(pred_offset = 5,\n",
    "                    input_size = 1,\n",
    "                    output_size = 1,\n",
    "                    max_seq_length = 5,\n",
    "                    embedding_size = 3,\n",
    "                    num_basic_encoders = 2,\n",
    "                    num_atten_heads = 1,\n",
    "                    num_basic_decoders = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2277ae3-628e-4777-9878-cb0a3e92181e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_warmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepsilon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mstandardize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/02 - Philipp Stauffenberg/Columbia|Documents/05 - Fall 22/04 - Machine Learning and High Dimensional Data Mining/06 - Project/TS_Transformer/transformer.py:71\u001b[0m, in \u001b[0;36mTransformer.start_training\u001b[0;34m(self, sequence, loss, metric, epochs, batch_size, num_warmup_steps, optimizer_params, standardize, verbose, plot)\u001b[0m\n\u001b[1;32m     59\u001b[0m master_encoder_optimizer \u001b[38;5;241m=\u001b[39m ScheduledOptim(\n\u001b[1;32m     60\u001b[0m     optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaster_encoder\u001b[38;5;241m.\u001b[39mparameters(), betas\u001b[38;5;241m=\u001b[39m(beta1, beta2), eps\u001b[38;5;241m=\u001b[39mepsilon),\n\u001b[1;32m     61\u001b[0m     lr_mul\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     62\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_size,\n\u001b[1;32m     63\u001b[0m     n_warmup_steps\u001b[38;5;241m=\u001b[39mnum_warmup_steps)\n\u001b[1;32m     65\u001b[0m master_decoder_optimizer \u001b[38;5;241m=\u001b[39m ScheduledOptim(\n\u001b[1;32m     66\u001b[0m     optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaster_decoder\u001b[38;5;241m.\u001b[39mparameters(), betas\u001b[38;5;241m=\u001b[39m(beta1, beta2), eps\u001b[38;5;241m=\u001b[39mepsilon),\n\u001b[1;32m     67\u001b[0m     lr_mul\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     68\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_size,\n\u001b[1;32m     69\u001b[0m     n_warmup_steps\u001b[38;5;241m=\u001b[39mnum_warmup_steps)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvaluation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_torch(\u001b[38;5;28mself\u001b[39m, train_iter, loss, metric, epochs, master_encoder_optimizer, master_decoder_optimizer, verbose\u001b[38;5;241m=\u001b[39mverbose, plot\u001b[38;5;241m=\u001b[39mplot)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "model.start_training(sequence=sequence.reshape(-1, 1),\n",
    "                     loss=nn.MSELoss(),\n",
    "                     metric=nn.MSELoss(),\n",
    "                     epochs=100,\n",
    "                     batch_size=5,\n",
    "                     num_warmup_steps=100,\n",
    "                     optimizer_params={'beta1':0.01, 'beta2': 0.01, 'epsilon': 0.1},\n",
    "                     standardize=True,\n",
    "                     verbose=True,\n",
    "                     plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee485df-1d55-4ca2-852c-91722cf66b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38361976-4ac7-49d6-883d-57efa83f5277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
